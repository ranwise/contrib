# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - ml
    - python
title: 'Alexander Hendorf: Speech Synthesis with Tacotron2 and PyTorch | PyData Amsterdam 2019'
language: English
recordingDate: 1561408635
description: "Computer generated speech has existed for a while, parameters being painfully engineered by hand. Deep Learning models can be efficient at learning inherent features of data - how well does this work out for audio?\n\nThere are different DL-models as WaveNet, SampleRNN and Tacotron2. After a quick overview, I'm going to focus on Tacotron2 - how it works, it's benefits and how to implement it with PyTorch.\n\nWith Tacotron2 we make no assumption what features should be passed to the vocoder. All there is required are audio-snippets and corresponding text. Non-English language audio datasets are hard to get. I had to generate my own dataset. This talk will also cover how I have created my own dataset in a semi-automatic efficiently with tools like audiotok and methods as Speaker diarisation.\n\nThe talks will feature synthesised speech audio demos. I will also cover some failures and reason about them.\n\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases."
