# Editing guidelines: https://github.com/watch-devtube/contrib/#how-to-edit-video-metadata

tags:
    - ml
    - performance
    - containers
    - kubernetes
    - architecture
title: 'Hyperparameter Tuning Using Kubeflow - Richard Liu, Google & Johnu George, Cisco Systems'
language: English
recordingDate: 1562351629
description: "Hyperparameter Tuning Using Kubeflow - Richard Liu, Google & Johnu George, Cisco Systems \n\nJoin us for KubeCon + CloudNativeCon in San Diego November 18 - 21. Learn more at https://bit.ly/2WdUyQ6. The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy and all of the other CNCF-hosted projects. \n\nIn machine learning, hyperparameter tuning refers to the process of finding the optimal constraints for training models. Choosing optimal hyperparameters can drastically improve the performance of a model, but the search space grows exponentially with the addition of new hyperparameters. A closely related subfield of automated machine learning is neural architecture search (NAS). In recent research, networks generated by NAS algorithms can even outperform handcrafted neural networks. However, like hyperparameter tuning, the process can be time-consuming and expensive. We present Katib - a Kubernetes-native automated machine learning platform for hyperparameter tuning and NAS. Part of the Kubeflow platform, Katib offers a rich set of management APIs in the form of custom resources. We will demonstrate how to configure and run an experiment and compare performance in Katibâ€™s UI dashboard.\n\nhttps://sched.co/NrnY"
